{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine dataset\n",
    "genuine_data = pd.read_csv(\"genuine_with_label.csv\")\n",
    "\n",
    "# Malicious dataset\n",
    "malicious_data = pd.read_csv(\"malicious_with_label.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array exported to file\n"
     ]
    }
   ],
   "source": [
    "number_range = [50,100,150,200,250,300,350,400,450,500]\n",
    "\n",
    "LR_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "LR_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "KNN_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "KNN_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "SVM_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "SVM_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "\n",
    "\n",
    "for i in number_range:\n",
    "    combined_data= pd.concat([genuine_data.iloc[0:i],malicious_data.iloc[0:i]]).reset_index(drop=True)\n",
    "    # combined_data= pd.concat([genuine_data,malicious_data]).reset_index(drop=True)\n",
    "    # combined_data= pd.concat([genuine_data.iloc[0:150],malicious_data.iloc[0:150]]).reset_index(drop=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    combined_data[['Duration', 'Received echo requests']] = scaler.fit_transform(combined_data[['Duration', 'Received echo requests']])\n",
    "    combined_data.head()\n",
    "\n",
    "\n",
    "\n",
    "    X = combined_data.drop(['Attack'], axis=1)\n",
    "    y = combined_data['Attack']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=177,stratify =y)\n",
    "    \n",
    "    ## Logistic Regression ########################\n",
    "\n",
    "\n",
    "    #Time for Training the model\n",
    "    logmodel = LogisticRegression()\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    logmodel.fit(X_train,y_train)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    LR_Taining_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    #-----------------\n",
    "\n",
    "    #Time for testing/Predicting the data\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    predictions = logmodel.predict(X_test)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    LR_Testing_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test,predictions)\n",
    "    LR_acuracy_AND_estimationTime.append([LR_Taining_timer_ns,LR_Testing_timer_ns,accuracy])\n",
    "    CM = confusion_matrix(y_test,predictions)\n",
    "\n",
    "    CM_temp_array = []\n",
    "    for m in CM:\n",
    "        for j in m:\n",
    "            CM_temp_array.append(j)\n",
    "    LR_confusionMatrix.append(CM_temp_array)\n",
    "\n",
    "\n",
    "\n",
    "    ## K-NN########################\n",
    "\n",
    "    #Time for Training the model\n",
    "    knn  = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    knn.fit(X_train,y_train)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    KNN_Training_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    #Time for testing/Predicting the data\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    KNN_Testing_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test,pred)\n",
    "    KNN_acuracy_AND_estimationTime.append([KNN_Training_timer_ns,KNN_Testing_timer_ns,accuracy])\n",
    "\n",
    "    CM = confusion_matrix(y_test,pred)\n",
    "    CM_temp_array = []\n",
    "    for m in CM:\n",
    "        for j in m:\n",
    "            CM_temp_array.append(j)\n",
    "    KNN_confusionMatrix.append(CM_temp_array)\n",
    "\n",
    "\n",
    "    ## SVM ###################\n",
    "\n",
    "    #Time for Training the model\n",
    "    model = SVC()\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    SVM_train_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    #-------------------------------\n",
    "\n",
    "    #Time for testing/Predicting the data\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    svmPrediction = model.predict(X_test)\n",
    "    confusion_matrix(y_test,svmPrediction)\n",
    "\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    SVM_Test_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test,svmPrediction)\n",
    "    SVM_acuracy_AND_estimationTime.append([SVM_train_timer_ns,SVM_Test_timer_ns,accuracy])\n",
    "\n",
    "\n",
    "    CM = confusion_matrix(y_test,svmPrediction)\n",
    "    CM_temp_array = []\n",
    "    for m in CM:\n",
    "        for j in m:\n",
    "            CM_temp_array.append(j)\n",
    "    SVM_confusionMatrix.append(CM_temp_array)\n",
    "    \n",
    "\n",
    "LR_CM = pd.DataFrame(LR_confusionMatrix)\n",
    "LR_CM.to_csv('1-LR_CM.csv',header = False, index= False)\n",
    "\n",
    "KNN_CM = pd.DataFrame(KNN_confusionMatrix)\n",
    "KNN_CM.to_csv('2-KNN_CM.csv',header = False, index= False)\n",
    "\n",
    "SVM_CM = pd.DataFrame(SVM_confusionMatrix)\n",
    "SVM_CM.to_csv('3-SVM_CM.csv',header = False, index= False)\n",
    "\n",
    "\n",
    "LR_A_EstimationTime = pd.DataFrame(LR_acuracy_AND_estimationTime)\n",
    "LR_A_EstimationTime.to_csv('1-LR_Accuracy_EstimationTime.csv',header = False, index= False)\n",
    "\n",
    "KNN_A_EstimationTime = pd.DataFrame(KNN_acuracy_AND_estimationTime)\n",
    "KNN_A_EstimationTime.to_csv('2-KNN_Accuracy_EstimationTime.csv',header = False, index= False)\n",
    "\n",
    "SVM_A_EstimationTime = pd.DataFrame(SVM_acuracy_AND_estimationTime)\n",
    "SVM_A_EstimationTime.to_csv('3-SVM_Accuracy_EstimationTime.csv',header = False, index= False)\n",
    "\n",
    "print('Array exported to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Duration  Received echo requests  Attack\n",
      "0      0.000020                       1       0\n",
      "1      1.000660                       2       0\n",
      "2      2.003343                       3       0\n",
      "3      3.004835                       4       0\n",
      "4      4.008014                       5       0\n",
      "..          ...                     ...     ...\n",
      "995  252.560472                  292420       1\n",
      "996  331.340049                  386435       1\n",
      "997   34.392835                   38361       1\n",
      "998  446.223051                  499272       1\n",
      "999  114.058119                  131873       1\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "number_range = [50,100,150,200,250,300,350,400,450,500]\n",
    "\n",
    "LR_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "LR_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "KNN_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "KNN_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "SVM_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "SVM_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_data= pd.concat([genuine_data,malicious_data]).reset_index(drop=True)\n",
    "# combined_data= pd.concat([genuine_data.iloc[0:150],malicious_data.iloc[0:150]]).reset_index(drop=True)\n",
    "print (combined_data)\n",
    "scaler = MinMaxScaler()\n",
    "combined_data[['Duration', 'Received echo requests']] = scaler.fit_transform(combined_data[['Duration', 'Received echo requests']])\n",
    "combined_data.head()\n",
    "\n",
    "\n",
    "\n",
    "X = combined_data.drop(['Attack'], axis=1)\n",
    "y = combined_data['Attack']\n",
    "\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data.to_csv(\"dataset.csv\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('my_array.csv', 'w') as my_file:\n",
    "#         for i in LR_confusionMatrix:\n",
    "# #             for j in i: \n",
    "#             np.savetxt(my_file,i)\n",
    "    \n",
    "my_df = pd.DataFrame(LR_confusionMatrix)\n",
    "my_df.to_csv('my_array.csv',header = False, index= False)\n",
    "print('Array exported to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: Attack, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.99625, 0.975  , 0.95875, 0.95625, 0.95625]),\n",
       " 'Mean Training Accuracy': 96.85,\n",
       " 'Training Precision scores': array([1., 1., 1., 1., 1.]),\n",
       " 'Mean Training Precision': 1.0,\n",
       " 'Training Recall scores': array([0.9925, 0.95  , 0.9175, 0.9125, 0.9125]),\n",
       " 'Mean Training Recall': 0.9369999999999999,\n",
       " 'Training F1 scores': array([0.99623588, 0.97435897, 0.95697523, 0.95424837, 0.95424837]),\n",
       " 'Mean Training F1 Score': 0.9672133638227829,\n",
       " 'Validation Accuracy scores': array([0.72 , 0.98 , 0.965, 0.94 , 0.95 ]),\n",
       " 'Mean Validation Accuracy': 91.1,\n",
       " 'Validation Precision scores': array([0.64102564, 1.        , 1.        , 1.        , 1.        ]),\n",
       " 'Mean Validation Precision': 0.9282051282051281,\n",
       " 'Validation Recall scores': array([1.  , 0.96, 0.93, 0.88, 0.9 ]),\n",
       " 'Mean Validation Recall': 0.9339999999999999,\n",
       " 'Validation F1 scores': array([0.78125   , 0.97959184, 0.96373057, 0.93617021, 0.94736842]),\n",
       " 'Mean Validation F1 Score': 0.9216222081002939}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_result = cross_validation(LogisticRegression(), X, y, 5)\n",
    "LR_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.9975, 0.9975, 0.9975, 0.9975, 0.9975]),\n",
       " 'Mean Training Accuracy': 99.75000000000001,\n",
       " 'Training Precision scores': array([1., 1., 1., 1., 1.]),\n",
       " 'Mean Training Precision': 1.0,\n",
       " 'Training Recall scores': array([0.995, 0.995, 0.995, 0.995, 0.995]),\n",
       " 'Mean Training Recall': 0.9949999999999999,\n",
       " 'Training F1 scores': array([0.99749373, 0.99749373, 0.99749373, 0.99749373, 0.99749373]),\n",
       " 'Mean Training F1 Score': 0.9974937343358394,\n",
       " 'Validation Accuracy scores': array([0.685, 0.995, 1.   , 0.995, 0.99 ]),\n",
       " 'Mean Validation Accuracy': 93.30000000000001,\n",
       " 'Validation Precision scores': array([0.61349693, 1.        , 1.        , 1.        , 1.        ]),\n",
       " 'Mean Validation Precision': 0.9226993865030675,\n",
       " 'Validation Recall scores': array([1.  , 0.99, 1.  , 0.99, 0.98]),\n",
       " 'Mean Validation Recall': 0.9920000000000002,\n",
       " 'Validation F1 scores': array([0.76045627, 0.99497487, 1.        , 0.99497487, 0.98989899]),\n",
       " 'Mean Validation F1 Score': 0.9480610024813935}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_result = cross_validation(KNeighborsClassifier(n_neighbors=5), X, y, 5)\n",
    "KNN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training Accuracy scores': array([0.9975 , 0.975  , 0.97625, 0.98   , 0.98   ]),\n",
       " 'Mean Training Accuracy': 98.17499999999998,\n",
       " 'Training Precision scores': array([1., 1., 1., 1., 1.]),\n",
       " 'Mean Training Precision': 1.0,\n",
       " 'Training Recall scores': array([0.995 , 0.95  , 0.9525, 0.96  , 0.96  ]),\n",
       " 'Mean Training Recall': 0.9635,\n",
       " 'Training F1 scores': array([0.99749373, 0.97435897, 0.97567222, 0.97959184, 0.97959184]),\n",
       " 'Mean Training F1 Score': 0.9813417194546072,\n",
       " 'Validation Accuracy scores': array([0.715, 0.985, 0.98 , 0.965, 0.965]),\n",
       " 'Mean Validation Accuracy': 92.19999999999999,\n",
       " 'Validation Precision scores': array([0.63694268, 1.        , 1.        , 1.        , 1.        ]),\n",
       " 'Mean Validation Precision': 0.9273885350318471,\n",
       " 'Validation Recall scores': array([1.  , 0.97, 0.96, 0.93, 0.93]),\n",
       " 'Mean Validation Recall': 0.958,\n",
       " 'Validation F1 scores': array([0.77821012, 0.98477157, 0.97959184, 0.96373057, 0.96373057]),\n",
       " 'Mean Validation F1 Score': 0.934006933393329}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_result = cross_validation(SVC(), X, y, 5)\n",
    "SVM_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
