{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genuine dataset\n",
    "genuine_data = pd.read_csv(\"genuine_with_label.csv\")\n",
    "\n",
    "# Malicious dataset\n",
    "malicious_data = pd.read_csv(\"malicious_with_label_spoofed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_range = [50,100,150,200,250,300,350,400,450,500]\n",
    "\n",
    "LR_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "LR_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "KNN_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "KNN_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "SVM_acuracy_AND_estimationTime = [[\"Train_Estimation\",\"Test_Estimation\",\"Accuracy\"]]\n",
    "SVM_confusionMatrix = [['TN','FP','FN',\"TP\"]]\n",
    "\n",
    "\n",
    "\n",
    "for i in number_range:\n",
    "    combined_data= pd.concat([genuine_data.iloc[0:i],malicious_data.iloc[0:i]]).reset_index(drop=True)\n",
    "    # combined_data= pd.concat([genuine_data,malicious_data]).reset_index(drop=True)\n",
    "    # combined_data= pd.concat([genuine_data.iloc[0:150],malicious_data.iloc[0:150]]).reset_index(drop=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "#     combined_data[['Duration', 'Received echo requests']] = scaler.fit_transform(combined_data[['Duration', 'Received echo requests']])\n",
    "    combined_data.head()\n",
    "\n",
    "\n",
    "\n",
    "    X = combined_data.drop(['Attack'], axis=1)\n",
    "    y = combined_data['Attack']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=177,stratify =y)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    ## Logistic Regression ########################\n",
    "\n",
    "\n",
    "    #Time for Training the model\n",
    "    logmodel = LogisticRegression()\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    logmodel.fit(X_train,y_train)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    LR_Taining_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    #-----------------\n",
    "\n",
    "    #Time for testing/Predicting the data\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    predictions = logmodel.predict(X_test)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    LR_Testing_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test,predictions)\n",
    "    LR_acuracy_AND_estimationTime.append([LR_Taining_timer_ns,LR_Testing_timer_ns,accuracy])\n",
    "    CM = confusion_matrix(y_test,predictions)\n",
    "\n",
    "    CM_temp_array = []\n",
    "    for m in CM:\n",
    "        for j in m:\n",
    "            CM_temp_array.append(j)\n",
    "    LR_confusionMatrix.append(CM_temp_array)\n",
    "\n",
    "\n",
    "\n",
    "    ## K-NN########################\n",
    "\n",
    "    #Time for Training the model\n",
    "    knn  = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    knn.fit(X_train,y_train)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    KNN_Training_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    #----------------------------\n",
    "\n",
    "    #Time for testing/Predicting the data\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    KNN_Testing_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test,pred)\n",
    "    KNN_acuracy_AND_estimationTime.append([KNN_Training_timer_ns,KNN_Testing_timer_ns,accuracy])\n",
    "\n",
    "    CM = confusion_matrix(y_test,pred)\n",
    "    CM_temp_array = []\n",
    "    for m in CM:\n",
    "        for j in m:\n",
    "            CM_temp_array.append(j)\n",
    "    KNN_confusionMatrix.append(CM_temp_array)\n",
    "\n",
    "\n",
    "    ## SVM ###################\n",
    "\n",
    "    #Time for Training the model\n",
    "    model = SVC()\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    SVM_train_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    #-------------------------------\n",
    "\n",
    "    #Time for testing/Predicting the data\n",
    "\n",
    "    start_counter_ns = time.perf_counter()\n",
    "\n",
    "    svmPrediction = model.predict(X_test)\n",
    "    confusion_matrix(y_test,svmPrediction)\n",
    "\n",
    "\n",
    "    end_counter_ns = time.perf_counter()\n",
    "    SVM_Test_timer_ns = end_counter_ns - start_counter_ns\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test,svmPrediction)\n",
    "    SVM_acuracy_AND_estimationTime.append([SVM_train_timer_ns,SVM_Test_timer_ns,accuracy])\n",
    "\n",
    "\n",
    "    CM = confusion_matrix(y_test,svmPrediction)\n",
    "    CM_temp_array = []\n",
    "    for m in CM:\n",
    "        for j in m:\n",
    "            CM_temp_array.append(j)\n",
    "    SVM_confusionMatrix.append(CM_temp_array)\n",
    "    \n",
    "\n",
    "LR_CM = pd.DataFrame(LR_confusionMatrix)\n",
    "LR_CM.to_csv('1-LR_CM.csv',header = False, index= False)\n",
    "\n",
    "KNN_CM = pd.DataFrame(KNN_confusionMatrix)\n",
    "KNN_CM.to_csv('2-KNN_CM.csv',header = False, index= False)\n",
    "\n",
    "SVM_CM = pd.DataFrame(SVM_confusionMatrix)\n",
    "SVM_CM.to_csv('3-SVM_CM.csv',header = False, index= False)\n",
    "\n",
    "\n",
    "LR_A_EstimationTime = pd.DataFrame(LR_acuracy_AND_estimationTime)\n",
    "LR_A_EstimationTime.to_csv('1-LR_Accuracy_EstimationTime.csv',header = False, index= False)\n",
    "\n",
    "KNN_A_EstimationTime = pd.DataFrame(KNN_acuracy_AND_estimationTime)\n",
    "KNN_A_EstimationTime.to_csv('2-KNN_Accuracy_EstimationTime.csv',header = False, index= False)\n",
    "\n",
    "SVM_A_EstimationTime = pd.DataFrame(SVM_acuracy_AND_estimationTime)\n",
    "SVM_A_EstimationTime.to_csv('3-SVM_Accuracy_EstimationTime.csv',header = False, index= False)\n",
    "\n",
    "print('Array exported to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cell below needs to be run to scale the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "combined_data[['Duration', 'Received echo requests']] = scaler.fit_transform(combined_data[['Duration', 'Received echo requests']])\n",
    "\n",
    "X = combined_data.drop(['Attack'], axis=1)\n",
    "y = combined_data['Attack']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean()*100,\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean()*100,\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()*100\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LR_result = cross_validation(LogisticRegression(), X, y, 10)\n",
    "LR_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_result = cross_validation(KNeighborsClassifier(n_neighbors=5), X, y, 10)\n",
    "KNN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVM_result = cross_validation(SVC(), X, y, 10)\n",
    "SVM_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
